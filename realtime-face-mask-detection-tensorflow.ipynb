{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout\nfrom keras.models import Model, load_model\nfrom keras.callbacks import TensorBoard, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils import shuffle\nimport imutils\nimport numpy as np\n\nmodel = Sequential([\n    Conv2D(100, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    MaxPooling2D(2, 2),\n\n    Conv2D(100, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n\n    Flatten(),\n    Dropout(0.25),\n    Dense(50, activation='relu'),\n    Dense(2, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n\nTRAINING_DIR = \"E:/Thesis/SampleDataset/FaceMaskDataset/train\"\ntrain_datagen = ImageDataGenerator(rescale=1.0 / 255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                    batch_size=10,\n                                                    target_size=(150, 150))\n\nVALIDATION_DIR = \"E:/Thesis/SampleDataset/FaceMaskDataset/test\"\nvalidation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                              batch_size=20,\n                                                              target_size=(150, 150))\ncheckpoint = ModelCheckpoint('face_model-{epoch:03d}.model', monitor='val_loss', verbose=0, save_best_only=True,\n                             mode='auto')\n\nhistory = model.fit(train_generator,\n                              epochs=20,\n                              validation_data=validation_generator,\n                              callbacks=[checkpoint])","metadata":{"_uuid":"38847c5d-9528-4367-be14-3001ee73036c","_cell_guid":"41312d26-1e72-42fb-adf6-b0c9cb05ac41","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is a sample Python script.\nimport cv2\nimport numpy as np\nfrom keras.models import load_model\n\nmodel = load_model(\"E:/Thesis/PYCHARM_PROJECTS/tensorflowProject/FaceDetection/face_model-007.model\")\n\nlabels_dict = {0: 'without mask', 1: 'mask'}\ncolor_dict = {0: (0, 0, 255), 1: (0, 255, 0)}\n\nsize = 4\nwebcam = cv2.VideoCapture(0)  # Use camera 0\n\n# We load the xml file\nclassifier = cv2.CascadeClassifier('E:/INSTALLATION/ANACONDA/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n\nwhile True:\n    (rval, im) = webcam.read()\n    im = cv2.flip(im, 1, 1)  # Flip to act as a mirror\n\n    # Resize the image to speed up detection\n    mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n\n    # detect MultiScale / faces\n    faces = classifier.detectMultiScale(mini)\n\n    # Draw rectangles around each face\n    for f in faces:\n        (x, y, w, h) = [v * size for v in f]  # Scale the shapesize backup\n        # Save just the rectangle faces in SubRecFaces\n        face_img = im[y:y + h, x:x + w]\n        resized = cv2.resize(face_img, (150, 150))\n        normalized = resized / 255.0\n        reshaped = np.reshape(normalized, (1, 150, 150, 3))\n        reshaped = np.vstack([reshaped])\n        result = model.predict(reshaped)\n        # print(result)\n\n        label = np.argmax(result, axis=1)[0]\n\n        cv2.rectangle(im, (x, y), (x + w, y + h), color_dict[label], 2)\n        cv2.rectangle(im, (x, y - 40), (x + w, y), color_dict[label], -1)\n        cv2.putText(im, labels_dict[label], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n\n    # Show the image\n    cv2.imshow('LIVE', im)\n    key = cv2.waitKey(10)\n    # if Esc key is press then break out of the loop\n    if key == 27:  # The Esc key\n        break\n# Stop video\nwebcam.release()\n\n# Close all started windows\ncv2.destroyAllWindows()","metadata":{},"execution_count":null,"outputs":[]}]}